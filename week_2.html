<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Week 2 ‚Äì Internship Documentation</title>
  <link rel="stylesheet" href="style.css">
  <style>
    html { scroll-behavior: smooth; }

    .media-container {
      margin-top: 15px;
      margin-bottom: 25px;
    }

    .media-container img,
    .media-container video {
      width: 100%;
      max-width: 800px;
      border-radius: 10px;
      box-shadow: 0 4px 12px rgba(0,0,0,0.1);
    }
  </style>
</head>
<body>

  <div class="container layout">

    <!-- ===== Sidebar ===== -->
    <aside class="sidebar">
      <h3>Internship Timeline</h3>
      <ul class="timeline">
        <li><a href="week_1.html">Week 1</a></li>
        <li><a href="week_2.html" class="active">Week 2</a></li>
        <li><a href="week_3.html">Week 3</a></li>
        <li><a href="week_4.html">Week 4</a></li>
      </ul>
      <h3>Sections</h3>
      <ul class="timeline">
        <li><a href="#demo" class="section-link">Demo</a></li>
        <li><a href="#overview" class="section-link">Overview</a></li>
        <li><a href="#focus" class="section-link">Focus</a></li>
        <li><a href="#tasks" class="section-link">Tasks</a></li>
        <li><a href="#skills" class="section-link">Skills</a></li>
        <li><a href="#challenges" class="section-link">Challenges</a></li>
        <li><a href="#reflection" class="section-link">Reflection</a></li>
      </ul>
    </aside>

    <!-- ===== Main Content ===== -->
    <main>
      <header>
        <h1>Week 2: 19/01/2026 ‚Äì 25/01/2026</h1>
        <p>
          This week focused on building a fully functional locally hosted Grade 10 History RAG chatbot 
          using Ollama, ChromaDB, and Streamlit. The goal was to integrate embeddings, vector search, 
          and structured prompting into a working AI system.
        </p>
        <div class="nav">
          <a href="index.html">‚Üê Home</a>
        </div>
      </header>

      <hr>

      <!-- ===== Demo Section ===== -->
      <section id="demo">
        <h2>Project Demonstration</h2>

        <p>
          The chatbot was hosted locally using a remote GPU desktop connected through Ngrok. 
          Ollama was used to run LLaMA 3.1 (8B) for generation and nomic-embed-text for embeddings. 
          ChromaDB handled vector storage, and Streamlit provided the user interface.
        </p>

        <h3>Screenshot ‚Äì Locally Hosted Chatbot</h3>
        <div class="media-container">
          <img src="images/week2_chatbot_screenshot.png"
               alt="Locally Hosted Grade 10 History Chatbot">
          <p><em>Figure 1: Chatbot running locally using Ollama and Streamlit.</em></p>
        </div>

        <h3>Video Demonstration</h3>
        <div class="media-container">
          <video controls>
            <source src="videos/week2_chatbot_demo.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <p><em>Video 1: Demonstration of the chatbot answering textbook-based queries using RAG.</em></p>
        </div>

      </section>

      <hr>

      <section id="overview">
        <h2>Overview of Week 2</h2>
        <p>
          During Week 2, I transitioned from understanding LLM concepts to implementing a real Retrieval-Augmented Generation (RAG) system. 
          I built a chatbot that extracts text from a Grade 10 Bhutan History PDF, converts it into embeddings, 
          stores it in a vector database, and retrieves relevant context for answering user questions.
        </p>
      </section>

      <section id="focus">
        <h2>Focus of the Week</h2>
        <p>
          The primary focus was building a locally running AI system with proper architecture:
          PDF ‚Üí Chunking ‚Üí Embeddings ‚Üí ChromaDB ‚Üí Context Retrieval ‚Üí Prompt Engineering ‚Üí LLM Response.
          I also focused on debugging embedding errors, improving prompt structure, and implementing conversation memory.
        </p>
      </section>

      <hr>

      <section id="tasks">
        <h2>Tasks Completed</h2>
        <ul>
          <li>Built a Retrieval-Augmented Generation (RAG) pipeline from scratch.</li>
          <li>Implemented PDF text extraction and chunking using PyMuPDF.</li>
          <li>Integrated nomic-embed-text embedding model via Ollama.</li>
          <li>Stored embeddings in ChromaDB vector database.</li>
          <li>Created structured prompt engineering system for exam-ready answers.</li>
          <li>Implemented conversation memory in chatbot logic.</li>
          <li>Connected remote GPU desktop using Ngrok.</li>
          <li>Designed Streamlit-based interactive chatbot UI.</li>
          <li>Completed a DataCamp short course on AI fundamentals and model workflows.</li>
        </ul>
      </section>


      <hr>

      <section id="skills">
        <h2>Skills Learned / Developed</h2>
        <ul>
          <li>Retrieval-Augmented Generation (RAG) architecture</li>
          <li>Vector embeddings and similarity search</li>
          <li>ChromaDB database integration</li>
          <li>Prompt engineering for structured academic responses</li>
          <li>LLM hosting using Ollama</li>
          <li>Remote GPU deployment using Ngrok</li>
          <li>Frontend development using Streamlit</li>
          <li>AI workflow concepts from DataCamp course</li>
        </ul>
      </section>


      <section id="challenges">
        <h2>Challenges / Solutions</h2>
        <table>
          <thead>
            <tr>
              <th>Challenge</th>
              <th>Solution / Learning</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Embedding model not found (404 error)</td>
              <td>Learned to pull models properly using Ollama before calling embeddings.</td>
            </tr>
            <tr>
              <td>Irrelevant answers despite RAG</td>
              <td>Improved prompt structure and restricted responses strictly to context.</td>
            </tr>
            <tr>
              <td>Chatbot not understanding "elaborate" or "summarize"</td>
              <td>Added explicit conditional logic in the chatbot class for command detection.</td>
            </tr>
            <tr>
              <td>No memory between messages</td>
              <td>Implemented conversation history storage in Streamlit session state.</td>
            </tr>
          </tbody>
        </table>
      </section>

            <hr>

      <!-- ===== Source Code Section ===== -->
      <section id="code">
        <h2>Source Code</h2>

        <p>
          The complete implementation of the chatbot (RAG pipeline, embedding logic,
          Streamlit UI, and memory handling) is available in the Python file below.
        </p>

        <a href="app.py" class="code-link" target="_blank">
          üìÇ View Week 2 Chatbot Source Code (app.py)
        </a>

      </section>

      <hr>

      <hr>

      <section id="reflection">
        <h2>Reflection / Notes</h2>
        <ul>
          <li>This week shifted me from theory to real AI system engineering.</li>
          <li>I understood that LLM performance depends heavily on retrieval quality and prompt design.</li>
          <li>Debugging errors strengthened my understanding of model pipelines.</li>
          <li>Hosting locally gave me deeper insight into deployment and system architecture.</li>
        </ul>
      </section>

      <div class="nav">
        <a href="index.html">‚Üê Home</a>
        <a href="week_1.html">‚Üê Previous</a>
        <a href="week_3.html">Next ‚Üí</a>
      </div>

      <footer>
        ¬© 2026 Dawa Seldon
      </footer>
    </main>

  </div>

  <script>
    const currentPage = window.location.pathname.split("/").pop();
    document.querySelectorAll('.timeline a').forEach(link => {
      if (link.getAttribute('href') === currentPage) {
        link.classList.add('active');
      } else {
        link.classList.remove('active');
      }
    });
  </script>

</body>
</html>
